@inproceedings{10309562,
  author    = {Reig, Samantha and Carter, Elizabeth J. and Kirabo, Lynn and Fong, Terrence and Steinfeld, Aaron and Forlizzi, Jodi},
  booktitle = {2023 32nd IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)},
  title     = {Dreaming Up Smart Home Futures: A Story Completion Study},
  year      = {2023},
  volume    = {},
  number    = {},
  pages     = {1020-1027},
  keywords  = {Data privacy;Vacuum systems;Virtual assistants;Smart homes;Writing;Reflection;Encoding},
  doi       = {10.1109/RO-MAN57019.2023.10309562}
}

@inproceedings{10.1145/3544548.3580833,
  author    = {Reig, Samantha and Principe Cruz, Erica and Powers, Melissa M. and He, Jennifer and Chong, Timothy and Tham, Yu Jiang and Kratz, Sven and Robinson, Ava and Smith, Brian A. and Vaish, Rajan and Monroy-Hern\'{a}ndez, Andr\'{e}s},
  title     = {Supporting Piggybacked Co-Located Leisure Activities via Augmented Reality},
  year      = {2023},
  isbn      = {9781450394215},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3544548.3580833},
  doi       = {10.1145/3544548.3580833},
  abstract  = {Technology, especially the smartphone, is villainized for taking meaning and time away from in-person interactions and secluding people into “digital bubbles”. We believe this is not an intrinsic property of digital gadgets, but evidence of a lack of imagination in technology design. Leveraging augmented reality (AR) toward this end allows us to create experiences for multiple people, their pets, and their environments. In this work, we explore the design of AR technology that “piggybacks” on everyday leisure to foster co-located interactions among close ties (with other people and pets). We designed, developed, and deployed three such AR applications, and evaluated them through a 41-participant and 19-pet user study. We gained key insights about the ability of AR to spur and enrich interaction in new channels, the importance of customization, and the challenges of designing for the physical aspects of AR devices (e.g., holding smartphones). These insights guide design implications for the novel research space of co-located AR.},
  booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  articleno = {788},
  numpages  = {15},
  keywords  = {augmented/mixed reality, co-located interaction, embodied interaction, everyday leisure, human–pet–computer interaction, piggybacking},
  location  = {<conf-loc>, <city>Hamburg</city>, <country>Germany</country>, </conf-loc>},
  series    = {CHI '23}
}

Why does this one insist on being at the top?

@inproceedings{9702757,
  author   = {Reig, Samantha and Fong, Terrence and Forlizzi, Jodi and Steinfeld, Aaron},
  journal  = {IEEE Transactions on Human-Machine Systems},
  title    = {Theory and Design Considerations for the User Experience of Smart Environments},
  year     = {2022},
  volume   = {52},
  number   = {3},
  pages    = {522-535},
  keywords = {Smart homes;Human computer interaction;Task analysis;Bibliographies;Artificial intelligence;Virtual assistants;Software;Human-agent interaction;human–computer interaction (HCI);human–robot interaction;smart environments;user experience},
  doi      = {10.1109/THMS.2022.3142112}
}


@inproceedings{10.5555/3523760.3523810,
  author    = {Bejarano, Alexandra and Reig, Samantha and Senapati, Priyanka and Williams, Tom},
  title     = {You Had Me at Hello: The Impact of Robot Group Presentation Strategies on Mental Model Formation},
  year      = {2022},
  publisher = {IEEE Press},
  abstract  = {Research has shown how the connections between robots' minds, bodies, and identities can be configured and performed in a variety of ways. In this work, we consider group identity observables: the set of design cues that robot groups use to perform different identity configurations. We explore how group identity observables lead observers to develop different mental models of robot groups. Specifically, we make four key contributions: (1) we define, conceptualize, and taxonomize group identity observables; (2) we use Grounded Theory-informed analysis of qualitative data to produce a taxonomy of users' mental models invoked by variation in those observables; (3) we empirically demonstrate (n=166) how variations in observables lead to different mental models; and (4) we further demonstrate how variations in those observables, and the mental models they evoke, influence key group dynamics constructs like entitativity.},
  booktitle = {Proceedings of the 2022 ACM/IEEE International Conference on Human-Robot Interaction},
  pages     = {363–371},
  numpages  = {9},
  keywords  = {robot groups, mental models, identity performance strategies, human-robot interaction},
  location  = {Sapporo, Hokkaido, Japan},
  series    = {HRI '22}
}

@inproceedings{10.1145/3472307.3484664,
  author    = {Reig, Samantha and Carter, Elizabeth Jeanne and Kirabo, Lynn and Fong, Terrence and Steinfeld, Aaron and Forlizzi, Jodi},
  title     = {Smart Home Agents and Devices of Today and Tomorrow: Surveying Use and Desires},
  year      = {2021},
  isbn      = {9781450386203},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3472307.3484664},
  doi       = {10.1145/3472307.3484664},
  abstract  = {How are people using current smart home technologies, and how do they conceptualize future ones that are more interconnected and more capable than those available today? We deployed an online survey study to 150 participants to investigate use of and opinions about smart speakers, home robots, virtual assistants, and other smart home devices. We also gauged how impressions of connected smart home devices are shaped by the way the devices interact with one another. Through a mixed-methods qualitative and quantitative approach, we found that people mostly use single devices for single functions, and have simple and brief interactions with virtual assistants. However, they imagine their future devices to have more control over the physical environment (i.e., interact with each other) and envision them interacting with people in more socially complex ways. These findings motivate design considerations and research directions for connected smart home technologies.},
  booktitle = {Proceedings of the 9th International Conference on Human-Agent Interaction},
  pages     = {300–304},
  numpages  = {5},
  keywords  = {survey, smart homes, smart environments, human-robot interaction, human-agent interaction, IoT},
  location  = {<conf-loc>, <city>Virtual Event</city>, <country>Japan</country>, </conf-loc>},
  series    = {HAI '21}
}

@inproceedings{10.1145/3461778.3462036,
  author    = {Reig, Samantha and Luria, Michal and Forberger, Elsa and Won, Isabel and Steinfeld, Aaron and Forlizzi, Jodi and Zimmerman, John},
  title     = {Social Robots in Service Contexts: Exploring the Rewards and Risks of Personalization and Re-embodiment},
  year      = {2021},
  isbn      = {9781450384766},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3461778.3462036},
  doi       = {10.1145/3461778.3462036},
  abstract  = {Social agents and robots are moving into front-line positions in brick and mortar services, taking on roles where they directly interact with customers. These agents could potentially recognize customers to personalize service. Will customers like this, or might they feel monitored and profiled? Robots could also re-embody (move their “personality” between one body and another) in order to take on multiple roles that are typically performed by different people. Will this make customers feel more taken care of, or will it raise concerns about the robot’s competence and expertise? Our work investigates when robots should and should not recognize customers and re-embody. Our online study used storyboards to present possible future interactions between robots and customers across several different service contexts. Our findings suggest that people generally accept robots identifying customers and taking on vastly different roles. However, in some contexts, these robot behaviors seem creepy and untrustworthy.},
  booktitle = {Proceedings of the 2021 ACM Designing Interactive Systems Conference},
  pages     = {1390–1402},
  numpages  = {13},
  keywords  = {storyboards, re-embodiment, personalization, interaction design, human-robot interaction, human-agent interaction},
  location  = {Virtual Event, USA},
  series    = {DIS '21}
}

@inproceedings{10.1145/3434073.3444659,
  author    = {Reig, Samantha and Carter, Elizabeth J. and Fong, Terrence and Forlizzi, Jodi and Steinfeld, Aaron},
  title     = {Flailing, Hailing, Prevailing: Perceptions of Multi-Robot Failure Recovery Strategies},
  year      = {2021},
  isbn      = {9781450382892},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3434073.3444659},
  doi       = {10.1145/3434073.3444659},
  abstract  = {We explored different ways in which a multi-robot system might recover after one robot experiences a failure. We compared four recovery conditions: Update (a robot fixes its error and continues the task), Re-embody (a robot transfers its intelligence to a different body), Call (the failed robot summons a second robot to take its place), and Sense (a second robot detects the failure and proactively takes the place of the first robot). We found that trust in the system and perceived competence of the system were higher when a single robot recovered from a failure on its own (by updating or re-embodying) than when a second robot took over the task. We also found evidence that two robots that used the same socially interactive intelligence were perceived more similarly than two robots with different intelligences. Finally, our study revealed a relationship between how people perceive the agency of a robot and how they perceive the performance of the system.},
  booktitle = {Proceedings of the 2021 ACM/IEEE International Conference on Human-Robot Interaction},
  pages     = {158–167},
  numpages  = {10},
  keywords  = {trust, recovery, re-embodiment, multi-robot interaction, failure},
  location  = {Boulder, CO, USA},
  series    = {HRI '21}
}

@inproceedings{10.1145/3357236.3395479,
  author    = {Cambre, Julia and Reig, Samantha and Kravitz, Queenie and Kulkarni, Chinmay},
  title     = {"All Rise for the AI Director": Eliciting Possible Futures of Voice Technology through Story Completion},
  year      = {2020},
  isbn      = {9781450369749},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3357236.3395479},
  doi       = {10.1145/3357236.3395479},
  abstract  = {How might the capabilities of voice assistants several decades in the future shape human society? To anticipate the space of possible futures for voice assistants, we asked 149 participants to each complete a story based on a brief story stem set in the year 2050 in one of five different contexts: the home, doctor's office, school, workplace, and public transit. Story completion as a method elicits participants' visions of possible futures, unconstrained by their understanding of current technological capabilities, but still reflective of current sociocultural values. Through a thematic analysis, we find these stories reveal the extremes of the capabilities and concerns of today's voice assistants---and artificial intelligence---such as improving efficiency and offering instantaneous support, but also replacing human jobs, eroding human agency, and causing harm through malfunction. We conclude by discussing how these speculative visions might inform and inspire the design of voice assistants and other artificial intelligence.},
  booktitle = {Proceedings of the 2020 ACM Designing Interactive Systems Conference},
  pages     = {2051–2064},
  numpages  = {14},
  keywords  = {voice assistant, story completion, speculative design, cui, conversational user interface},
  location  = {<conf-loc>, <city>Eindhoven</city>, <country>Netherlands</country>, </conf-loc>},
  series    = {DIS '20}
}

@inproceedings{10.1145/3319502.3374795,
  author    = {Reig, Samantha and Luria, Michal and Wang, Janet Z. and Oltman, Danielle and Carter, Elizabeth Jeanne and Steinfeld, Aaron and Forlizzi, Jodi and Zimmerman, John},
  title     = {Not Some Random Agent: Multi-person Interaction with a Personalizing Service Robot},
  year      = {2020},
  isbn      = {9781450367462},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3319502.3374795},
  doi       = {10.1145/3319502.3374795},
  abstract  = {Service robots often perform their main functions in public settings, interacting with more than one person at a time. How these robots should handle the affairs of individual users while also behaving appropriately when others are present is an open question. One option is to design for flexible agent embodiment: letting agents take control of different robots as people move between contexts. Through structured User Enactments, we explored how agents embodied within a single robot might interact with multiple people. Participants interacted with a robot embodied by a singular service agent, agents that re-embody in different robots and devices, and agents that co-embody within the same robot. Findings reveal key insights about the promise of re-embodiment and co-embodiment as design paradigms as well as what people value during interactions with service robots that use personalization.},
  booktitle = {Proceedings of the 2020 ACM/IEEE International Conference on Human-Robot Interaction},
  pages     = {289–297},
  numpages  = {9},
  keywords  = {service, re-embodiment, personalization, interaction design, human-robot interaction, human-agent interaction, groups},
  location  = {Cambridge, United Kingdom},
  series    = {HRI '20}
}

@inproceedings{10.1145/3319502.3374794,
  author    = {Carter, Elizabeth J. and Reig, Samantha and Tan, Xiang Zhi and Laput, Gierad and Rosenthal, Stephanie and Steinfeld, Aaron},
  title     = {Death of a Robot: Social Media Reactions and Language Usage when a Robot Stops Operating},
  year      = {2020},
  isbn      = {9781450367462},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3319502.3374794},
  doi       = {10.1145/3319502.3374794},
  abstract  = {People take to social media to share their thoughts, joys, and sorrows. A recent popular trend has been to support and mourn people and pets that have died as well as other objects that have suffered catastrophic damage. As several popular robots have been discontinued, including the Opportunity Rover, Jibo, and Kuri, we are interested in how language used to mourn these robots compares to that to mourn people, animals, and other objects. We performed a study in which we asked participants to categorize deidentified Twitter reactions as referencing the death of a person, an animal, a robot, or another object. Most reactions were labeled as being about humans, which suggests that people use similar language to describe feelings for animate and inanimate entities. We used a natural language toolkit to analyze language from a larger set of tweets. A majority of tweets about Opportunity included second-person ("you") and gendered third-person pronouns (she/he versus it), but terms like "R.I.P" were reserved almost exclusively for humans and animals. Our findings suggest that people verbally mourn robots similarly to living things, but reserve some language for people.},
  booktitle = {Proceedings of the 2020 ACM/IEEE International Conference on Human-Robot Interaction},
  pages     = {589–597},
  numpages  = {9},
  keywords  = {social robots, social media, robots, death, anthropomorphism},
  location  = {Cambridge, United Kingdom},
  series    = {HRI '20}
}

@inproceedings{10.5555/3378680.3378699,
  author    = {Tan, Xiang Zhi and Reig, Samantha and Carter, Elizabeth J. and Steinfeld, Aaron},
  title     = {From one to another: how robot-robot interaction affects users' perceptions following a transition between robots},
  year      = {2020},
  isbn      = {9781538685556},
  publisher = {IEEE Press},
  abstract  = {Human-robot interactions that involve multiple robots are becoming common. It is crucial to understand how multiple robots should transfer information and transition users between them. To investigate this, we designed a 3 \texttimes{} 3 mixed-design study in which participants took part in a navigation task. Participants interacted with a stationary robot who summoned a functional (not explicitly social) mobile robot to guide them. Each participant experienced the three types of robot-robot interaction: representative (the stationary robot spoke to the participant on behalf of the mobile robot), direct (the stationary robot delivered the request to the mobile robot in a straightforward manner), and social (the stationary robot delivered the request to the mobile robot in a social manner). Each participant witnessed only one type of robot-robot communication: silent (the robots covertly communicated), explicit (the robots acknowledged that they were communicating), or reciting (the stationary robot said the request aloud). Our results show that it is possible to instill socialness in and improve likability of a functional robot by having a social robot interact socially with it. We also found that covertly exchanging information is less desirable than reciting information aloud.},
  booktitle = {Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction},
  pages     = {114–122},
  numpages  = {9},
  keywords  = {user study, transition, transfer, robots, multi-robot-human interaction, multi-robot, human-robot interaction},
  location  = {Daegu, Republic of Korea},
  series    = {HRI '19}
}

@inproceedings{10.1145/3308561.3353805,
  author    = {Tan, Xiang Zhi and Carter, Elizabeth J. and Reig, Samantha and Steinfeld, Aaron},
  title     = {Go That Way: Exploring Supplementary Physical Movements by a Stationary Robot When Providing Navigation Instructions},
  year      = {2019},
  isbn      = {9781450366762},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3308561.3353805},
  doi       = {10.1145/3308561.3353805},
  abstract  = {We describe an exploration of how kiosk-type stationary robots might provide navigation instructions for blind people. Inspired by a technique used by Orientation \&amp; Mobility experts in which a route is traced out on a person's palm, we developed five methods that supplement verbal instructions with physical movements. We explored the usability, strengths, and limitations of each of our methods in two exploratory studies with blind participants. One method, in which the robot used its entire arm to create path gestures while participants held its gripper, was preferred by 5 out of 8 blind participants and performed comparably on a recall task as a verbal-only instruction method. A closer approximation of the original palm method failed. We analyzed interview data to understand the reasons behind the failures and successes. We discuss the lessons learned from our studies about instruction methods, how robots in public settings can be useful for blind people, and the challenges of deploying such systems in public.},
  booktitle = {Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility},
  pages     = {299–311},
  numpages  = {13},
  keywords  = {navigation instructions, human-robot interaction, blindness, assistive robots},
  location  = {Pittsburgh, PA, USA},
  series    = {ASSETS '19}
}

@inproceedings{10.1109/RO-MAN46459.2019.8956412,
  author    = {Roth, Aaron M. and Reig, Samantha and Bhatt, Umang and Shulgach, Jonathan and Amin, Tamara and Doryab, Afsaneh and Fang, Fei and Veloso, Manuela},
  title     = {A Robot’s Expressive Language Affects Human Strategy and Perceptions in a Competitive Game},
  year      = {2019},
  publisher = {IEEE Press},
  url       = {https://doi.org/10.1109/RO-MAN46459.2019.8956412},
  doi       = {10.1109/RO-MAN46459.2019.8956412},
  abstract  = {As robots are increasingly endowed with social and communicative capabilities, they will interact with humans in more settings, both collaborative and competitive. We explore human-robot relationships in the context of a competitive Stackelberg Security Game. We vary humanoid robot expressive language (in the form of “encouraging” or “discouraging” verbal commentary) and measure the impact on participants’ rationality, strategy prioritization, mood, and perceptions of the robot. We learn that a robot opponent that makes discouraging comments causes a human to play a game less rationally and to perceive the robot more negatively. We also contribute a simple open source Natural Language Processing framework for generating expressive sentences, which was used to generate the speech of our autonomous social robot.},
  booktitle = {2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)},
  pages     = {1–8},
  numpages  = {8},
  location  = {New Delhi, India}
}

@inproceedings{10.1145/3322276.3322340,
  author    = {Luria, Michal and Reig, Samantha and Tan, Xiang Zhi and Steinfeld, Aaron and Forlizzi, Jodi and Zimmerman, John},
  title     = {Re-Embodiment and Co-Embodiment: Exploration of social presence for robots and conversational agents},
  year      = {2019},
  isbn      = {9781450358507},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3322276.3322340},
  doi       = {10.1145/3322276.3322340},
  abstract  = {Interactions with multiple conversational agents and social robots are becoming increasingly common. This raises new design challenges: Should agents and robots be modeled after humans, presenting their entity (i.e., social presence) as bound to a single body, or should they take advantage of non-human capabilities, such as moving their social presence from body to body across service touchpoints and contexts? We conducted a User Enactments study in which participants interacted with agents that had one social presence per body, that could re-embody (move their social presence from body to body), and that could co-embody (move their social presence into a body that already contains another). Reactions showed that participants felt comfortable with re-embodying agents, who created more seamless and efficient experiences. Yet situations that required expertise or concentration raised concerns about non-human behaviors. We report on our insights regarding collaboration and coordination with several agents in multi-step interactions.},
  booktitle = {Proceedings of the 2019 on Designing Interactive Systems Conference},
  pages     = {633–644},
  numpages  = {12},
  keywords  = {user enactments, social robots, re-embodiment, interaction design, embodied agents, conversational agents, co-embodiment},
  location  = {San Diego, CA, USA},
  series    = {DIS '19}
}

@inproceedings{10.1145/3239060.3239064,
  author    = {Reig, Samantha and Norman, Selena and Morales, Cecilia G. and Das, Samadrita and Steinfeld, Aaron and Forlizzi, Jodi},
  title     = {A Field Study of Pedestrians and Autonomous Vehicles},
  year      = {2018},
  isbn      = {9781450359467},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3239060.3239064},
  doi       = {10.1145/3239060.3239064},
  abstract  = {Autonomous vehicles have been in development for nearly thirty years and recently have begun to operate in real-world, uncontrolled settings. With such advances, more widespread research and evaluation of human interaction with autonomous vehicles (AV) is necessary. Here, we present an interview study of 32 pedestrians who have interacted with Uber AVs. Our findings are focused on understanding and trust of AVs, perceptions of AVs and artificial intelligence, and how the perception of a brand affects these constructs. We found an inherent relationship between favorable perceptions of technology and feelings of trust toward AVs. Trust in AVs was also influenced by a favorable interpretation of the company's brand and facilitated by knowledge about what AV technology is and how it might fit into everyday life. To our knowledge, this paper is the first to surface AV-related interview data from pedestrians in a natural, real-world setting.},
  booktitle = {Proceedings of the 10th International Conference on Automotive User Interfaces and Interactive Vehicular Applications},
  pages     = {198–209},
  numpages  = {12},
  keywords  = {trust, human-vehicle interaction, field study, Autonomous vehicles},
  location  = {Toronto, ON, Canada},
  series    = {AutomotiveUI '18}
}

@inproceedings{10.1145/3171221.3171243,
  author    = {Stoll, Brett and Reig, Samantha and He, Lucy and Kaplan, Ian and Jung, Malte F. and Fussell, Susan R.},
  title     = {Wait, Can You Move the Robot? Examining Telepresence Robot Use in Collaborative Teams},
  year      = {2018},
  isbn      = {9781450349536},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3171221.3171243},
  doi       = {10.1145/3171221.3171243},
  abstract  = {Telepresence robots provide remote team members with embodied presence, but whether this improves remote teammate participation, remote users' perceptions of team collaboration, or collocated members' perceptions of remote teammates is an open question. We conducted an experiment in which teams of two collocated members and one telepresent (remote) member solved a word puzzle requiring a translation key. We varied who had access to the key to examine effects of resource accessibility in distributed groups: in the Robot Information condition, the remote pilot (RP) possessed the key; in the Shared Information condition, all team members possessed the key; in the Local Information condition, only collocated participants (CPs) possessed the key. Audio transcripts were analyzed for differences in the number of words spoken by each team member. RPs spoke significantly less than CPs, especially when they lacked the translation key. RPs perceived greater task difficulty and less ease of communication than CPs. CPs rated other CPs as more trustworthy than RPs. This suggests an imbalance between collocated and remote collaborators that can negatively affect collaboration. We discuss implications for the design and use of telepresence robots in the workplace.},
  booktitle = {Proceedings of the 2018 ACM/IEEE International Conference on Human-Robot Interaction},
  pages     = {14–22},
  numpages  = {9},
  keywords  = {telepresence, remote collaboration, mobile robotic presence systems, experiment},
  location  = {Chicago, IL, USA},
  series    = {HRI '18}
}



LITTLE ONES

article{10.1145/3535271,
  author     = {Hammer, Jessica and Reig, Samantha},
  title      = {From individual rights to community obligations: a Jewish approach to speech},
  year       = {2022},
  issue_date = {July - August 2022},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {29},
  number     = {4},
  issn       = {1072-5520},
  url        = {https://doi.org/10.1145/3535271},
  doi        = {10.1145/3535271},
  journal    = {Interactions},
  month      = {jun},
  pages      = {30–34},
  numpages   = {5}
}

inproceedings{10.5555/3523760.3523925,
  author    = {Reig, Samantha and Carter, Elizabeth J. and Fong, Terrence and Steinfeld, Aaron and Forlizzi, Jodi},
  title     = {Perceptions of Explicitly vs. Implicitly Relayed Commands Between a Robot and Smart Speaker},
  year      = {2022},
  publisher = {IEEE Press},
  abstract  = {Designers of smart-home systems must make decisions about the perceived identities and interconnectedness of their various devices. To inform these decisions, we performed an online study to examine whether people perceive multiple devices in a smart home as different interfaces for the same system, devices that talk to each other, or independent devices. We manipulated the types of devices in the system (heterogeneous/homogeneous), how the devices relayed commands to each other (implicit/explicit), and the task requested. Participants were flexible in how they interpreted the devices, presenting an opportunity for designers to select a suitable model.},
  booktitle = {Proceedings of the 2022 ACM/IEEE International Conference on Human-Robot Interaction},
  pages     = {1012–1016},
  numpages  = {5},
  keywords  = {smart homes, smart environments, short vignette, internet of things, human-robot interaction, human-automation interaction},
  location  = {Sapporo, Hokkaido, Japan},
  series    = {HRI '22}
}

inproceedings{10.5555/3378680.3378876,
  author    = {Reig, Samantha and Forlizzi, Jodi and Steinfeld, Aaron},
  title     = {Leveraging robot embodiment to facilitate trust and smoothness},
  year      = {2020},
  isbn      = {9781538685556},
  publisher = {IEEE Press},
  abstract  = {Interactions with social robots in public and private spaces are becoming more and more common and varied. As this trend continues, it is important to understand how a robot's embodiment influences its ability to calibrate trust and comfort with its users and behave in accordance with social norms. This is especially true when one social intelligence embodies multiple physical robots (re-embodiment). We have conducted two studies---one quantitative and and one qualitative---which shed light on the way robots should be embodied and re-embodied by intelligences during different types of social interactions. This paper outlines our previous work on elucidating the role of embodiment in social interactions and experimenting with re-embodiment as a design paradigm, and it describes the directions in which we plan to take this research in the near future.},
  booktitle = {Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction},
  pages     = {742–744},
  numpages  = {3},
  keywords  = {trust, human-computer interaction, empirical study, embodiment, HCI},
  location  = {Daegu, Republic of Korea},
  series    = {HRI '19}
}
